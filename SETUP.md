# Инструкция по настройке и запуску проекта

Данная инструкция поможет вам настроить виртуальное окружение, установить необходимые зависимости и запустить проект кластеризации продуктов питания.

## Предварительные требования

- Python 3.12.3
- Java 8+ (необходим для PySpark)
- Доступ к интернету для загрузки зависимостей

## Настройка виртуального окружения

### 1. Создание виртуального окружения

#### Windows

```bash
# Создание виртуального окружения
python -m venv venv

# Активация виртуального окружения
venv\Scripts\activate
```

#### Linux/macOS

```bash
# Создание виртуального окружения
python3 -m venv venv

# Активация виртуального окружения
source venv/bin/activate
```

### 2. Установка зависимостей

После активации виртуального окружения установите необходимые зависимости:

```bash
pip install -r requirements.txt
```

### 3. Настройка переменных окружения для PySpark

#### Windows

```bash
# Установка переменных окружения для PySpark
set PYSPARK_PYTHON=python
set PYSPARK_DRIVER_PYTHON=python
```

#### Linux/macOS

```bash
# Установка переменных окружения для PySpark
export PYSPARK_PYTHON=python
export PYSPARK_DRIVER_PYTHON=python
```

## Запуск проекта

### 1. Запуск основного приложения

```bash
# Запуск с полным набором данных
python src/main.py

# Запуск с тестовым набором данных
python src/main.py --sample

# Запуск с сохранением модели
python src/main.py --save-model
```

### 2. Запуск тестов

#### Запуск всех тестов

```bash
# Запуск всех тестов с использованием unittest
python -m unittest discover tests

# Запуск всех тестов с использованием pytest
pytest tests/
```

#### Запуск конкретного теста

```bash
# Запуск конкретного теста с использованием unittest
python -m unittest tests.test_config

# Запуск конкретного теста с использованием pytest
pytest tests/test_config.py
```

#### Запуск тестов с отчетом о покрытии

```bash
# Запуск тестов с отчетом о покрытии
pytest --cov=src tests/
```

## Проверка работоспособности

После успешной установки и запуска проекта вы должны увидеть:

1. Логи о загрузке и обработке данных
2. Информацию о кластеризации
3. Сообщение о сохранении визуализаций в директории `results/`

## Возможные проблемы и их решения

### Проблемы с PySpark

Если у вас возникают проблемы с запуском PySpark, убедитесь, что:

1. Java установлена и доступна в PATH
2. Переменные окружения PYSPARK_PYTHON и PYSPARK_DRIVER_PYTHON установлены правильно
3. Версия PySpark совместима с вашей версией Java

Для проверки установки Java выполните:

```bash
java -version
```

### Проблемы с зависимостями

Если у вас возникают проблемы с установкой зависимостей, попробуйте:

```bash
# Обновить pip
pip install --upgrade pip

# Установить зависимости по одной
pip install pyspark==3.4.1
pip install pandas==2.1.0
# и т.д.
```

### Проблемы с Python 3.12.3

Если у вас возникают проблемы совместимости с Python 3.12.3, возможно, некоторые библиотеки еще не полностью поддерживают эту версию. В этом случае вы можете:

1. Создать виртуальное окружение с более старой версией Python (например, 3.10 или 3.11)
2. Или попробовать установить более новые версии библиотек (без указания конкретной версии в requirements.txt)

```bash
# Установка без указания версий
pip install pyspark pandas numpy matplotlib pytest pytest-cov configparser
```

## Дополнительная информация

Для получения дополнительной информации о проекте обратитесь к файлу README.md.
